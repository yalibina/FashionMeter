{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwfNeivsRFz2"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "!rm -rf FashionMeter/\n",
        "!git clone https://github.com/yalibina/FashionMeter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wSyUcm_S6qk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!cd FashionMeter && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFrygqDtTjpf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!cd FashionMeter/src/dataload &&  ./download.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "Kk0C5f47WR5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FashionMeter"
      ],
      "metadata": {
        "id": "y_ICDTvRWWCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfgAuNlZSWfx"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import wandb\n",
        "import torch\n",
        "from src.dataload.dataset import (\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    class_weights,\n",
        "    ids2label,\n",
        "    label2ids,\n",
        "    NUM_LABELS\n",
        ")\n",
        "from src.models.vit import LitViT\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "BpEdCXqIy9Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FashionMeter"
      ],
      "metadata": {
        "id": "pNbdu3x-dQ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "KjflafiMW7TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)"
      ],
      "metadata": {
        "id": "7Vn9wRBvVjjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = config['N_EPOCHS']\n",
        "LR = config['LR']\n",
        "WD = config['WD']\n",
        "CHECKPOINT_DIR = config['CHECKPOINT_DIR']\n",
        "PROJECT_NAME = config['PROJECT_NAME']\n",
        "MODEL_NAME = config['MODEL_NAME']\n",
        "\n",
        "print(config)"
      ],
      "metadata": {
        "id": "2DOUh19lVlRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = run.use_artifact('mmls05/FashionMeter/10epochs_lr1e-05_wd0.01:v0', type='model')\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "id": "-H4EajROusXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate base model"
      ],
      "metadata": {
        "id": "9dZLHMWJzP8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitViT(\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=ids2label,\n",
        "    label2id=label2ids,\n",
        "    class_weights=class_weights,\n",
        "    lr=LR,\n",
        "    weight_decay=WD,\n",
        ")\n",
        "lit_model.load_state_dict(torch.load('/content/FashionMeter/artifacts/10epochs_lr1e-05_wd0.01:v0/model.ckpt')['state_dict'])"
      ],
      "metadata": {
        "id": "ydLHy3cFuKBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model.to('cuda')\n",
        "lit_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "torch.manual_seed(42)\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_dataloader):\n",
        "        pixel_values = batch['pixel_values'].to(lit_model.device)\n",
        "        labels = batch['labels'].to(lit_model.device)\n",
        "        logits = lit_model(pixel_values)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time for inference:\", end - start)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "ZUitFj06vA3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate quantization"
      ],
      "metadata": {
        "id": "JMstG1svzVo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitViTQuantized(pl.LightningModule):\n",
        "    def __init__(self, quantized_model, num_labels):\n",
        "        super().__init__()\n",
        "        self.vit = quantized_model\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        return self.vit(pixel_values=pixel_values).logits\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "            pixel_values = batch[\"pixel_values\"]\n",
        "            logits = self(pixel_values)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            return preds"
      ],
      "metadata": {
        "id": "TtpQzR5DWQmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitViT(\n",
        "    num_labels=NUM_LABELS,\n",
        "    id2label=ids2label,\n",
        "    label2id=label2ids,\n",
        "    class_weights=class_weights,\n",
        "    lr=LR,\n",
        "    weight_decay=WD,\n",
        ")\n",
        "lit_model.load_state_dict(torch.load('/content/FashionMeter/artifacts/10epochs_lr1e-05_wd0.01:v0/model.ckpt')['state_dict'])\n",
        "\n",
        "hf_model = lit_model.vit\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(hf_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "lit_quant = LitViTQuantized(quantized_model=quantized_model, num_labels=lit_model.num_labels)\n"
      ],
      "metadata": {
        "id": "jJglpfBeYKIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lit_quant.device"
      ],
      "metadata": {
        "id": "t0EDeq8Ld_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
        "ModelSummary(lit_quant)"
      ],
      "metadata": {
        "id": "CjA_7EP3YgYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lit_quant.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "torch.manual_seed(42)\n",
        "start = time.time()\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_dataloader):\n",
        "        pixel_values = batch['pixel_values'].to(lit_quant.device)\n",
        "        labels = batch['labels'].to(lit_quant.device)\n",
        "        logits = lit_quant(pixel_values)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time for inference:\", end - start)\n",
        "\n",
        "# Optionally: evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "tVe-cONrXMUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lit_quant, \"lit_vit_quantized_full.pth\")"
      ],
      "metadata": {
        "id": "XgR2FM53yXSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "44wL8FxgictG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}